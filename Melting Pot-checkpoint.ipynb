{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Insights Melting Pot by Steven Au.\n",
    "This script ultimately replaces the excel file that was initially used to convert insights to a usable file also created by Steven Au.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "the_encode = 'utf_8_sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_import():\n",
    "    \"\"\"This is a proprietary function. We are importing the raw download from Insights.\n",
    "    HOWEVER, if the service is to change, this file reader function will read the entire file and SKIP the first row.\n",
    "    If yopu need to skip any more rows or not skip a row, simply put a number.\n",
    "    \n",
    "    Note: We are trying to get to header row. THe first row originally did not have a header row.\n",
    "    \n",
    "    Return:\n",
    "        df: The read excel dataframe, first sheet only!\n",
    "        the_file_name: THe file path with the extension name.\n",
    "    \"\"\"\n",
    "    the_file_name = input(\"xls or xlsx Filepath with name (You can drag and drop, remove the quote marks please!):\\n> \")\n",
    "    while 1:\n",
    "        try:\n",
    "            df = pd.read_excel(the_file_name,skiprows=1,encoding=the_encode)\n",
    "        except:\n",
    "            print(\"You've probably didn't delete the quotes or this is not an excel file.\")\n",
    "            print(\"You can delete the quotes by editing the file name\")\n",
    "            continue\n",
    "        return df, the_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_capture(dataframe, reg_calltype):\n",
    "    \"\"\"This function primarily captures the header column names\n",
    "\n",
    "    Parameters:\n",
    "        dataframe: The dataframe that we are using\n",
    "        reg_calltype: Has to be entered to the function as 'Units[)]' OR 'Revenue[)]' as a variable\n",
    "    \n",
    "    Retunr:\n",
    "        value_capturing: Returns the filtered dataframe columns according to either Units or Revenue\n",
    "    \"\"\"\n",
    "    value_capturing = dataframe.filter(regex=reg_calltype)\n",
    "    return value_capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melting_pot(the_dataframe, values_ID, var_calltype):\n",
    "    \"\"\"Meltss the corresponding dataframes to the values that are usable\n",
    "    This function is proprietary to get the corresponding column values that we need.\n",
    "    Note that it is well known that these values may change, even to the point of renamed or eliminated.\n",
    "    Since you are reading the source code, you can just modify the id_vars to reflect the appropriate columns.\n",
    "\n",
    "    Parameters:\n",
    "        the_dataframe: The raw pandas dataframe used.\n",
    "        values_ID: These are all from the value_capture function for its respective columns (We're only using the names)\n",
    "        var_calltype: needs to be specfied to either: Units OR Revenue\n",
    "\n",
    "    Returns:\n",
    "        melted: The dataframe melted per the original. Retains conditionally based on the parameters.\n",
    "    \n",
    "    Note: \n",
    "        var_name \"Partners\" is basically the Partner names of the evaluating column values.\n",
    "        That is, we have thrown all the column names together from the initial file.\n",
    "        And then we have renamed the columns we have captured as Partners.\n",
    "    \"\"\"\n",
    "    melted = the_dataframe.melt(id_vars= [\"eISBN13\",\"Series\",\"Volume\",\"Currency\"],\n",
    "                                var_name = \"Partners\",\n",
    "                                value_vars = values_ID,\n",
    "                                value_name = var_calltype\n",
    "                                )\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melting_process(melty, malty):\n",
    "    \"\"\"One time use melter using the two dataframes\n",
    "\n",
    "    Parameters:\n",
    "        melty: Uses dataframe A to create the initial dataframe for concatenation\n",
    "        malty: Uses dataframe B to create the secondary dataframe to be concatenated\n",
    "\n",
    "    Procedure:\n",
    "        Concats the two dataframes and then drops the duplicated column names.\n",
    "        With this new dataframe, drops all Revenue values that have a 0 (Keep all that do not equal 0)\n",
    "        Finally, replace all Partner values that have a \"Units\" in the name.\n",
    "\n",
    "    Returns:\n",
    "        The new pandas dataframe.    \n",
    "    \"\"\"\n",
    "    fin_melted = pd.concat([melty, malty],axis=1)\n",
    "    fin_melted = fin_melted.loc[:,~fin_melted.columns.duplicated()]\n",
    "    fin_melted = fin_melted[fin_melted.Revenue != 0]\n",
    "    fin_melted['Partners'] = fin_melted['Partners'].str.replace(' [(]Units[)]','')\n",
    "    return fin_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exporting_porcess(fin_melted, the_filename):\n",
    "    \"\"\"Exporting Process - the final step.\n",
    "    \n",
    "    Parameters:\n",
    "        fin_melted: The final melted and concatenated dataframe.\n",
    "        the_filename: From the original input, we are going to create the file name accordingly.\n",
    "    \n",
    "    Variables:\n",
    "        file_extension_name: This is an intermediary variable with the filename string split into a list.\n",
    "        path_name: This is the raw path. We're using file_extension_name variable to get the file name with extension.\n",
    "                    With this extension (The last value in the list), we are going to remove it to get the raw path.\n",
    "    \n",
    "    Final Procedure:\n",
    "        Use the melted dataframe, convert this to a CSV.\n",
    "            This uses the path_name we've extracted. Append the converted.csv and remove the index number column created by Pandas.\n",
    "    \"\"\"\n",
    "    file_extension_name = the_filename.split(\".\")\n",
    "    path_name = the_filename.strip(file_extension_name[-1])\n",
    "    print(\"The file path and name is as followed:\\n\"+path_name+\"-converted.csv\")\n",
    "    fin_melted.to_csv(path_name+\"-converted.csv\",index=None,encoding=the_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main program\n",
    "    Process:\n",
    "        1. File Import\n",
    "        2. Two Dataframes created from the import: Unit and Revenue\n",
    "        3. Melt each dataframe accordingly\n",
    "        4. Main procossing melting pot procedure\n",
    "        5. Export the file in CSV format (Due to the limitations of Excel)\n",
    "    \"\"\"\n",
    "    ### Step 1\n",
    "    insights_file, the_filename = file_import()\n",
    "    print(\"Step 1 completed.\")\n",
    "\n",
    "    ### Step 2\n",
    "    units_type = 'Units[)]'\n",
    "    revenue_type = 'Revenue[)]'\n",
    "    units = value_capture(insights_file,units_type)\n",
    "    revenue = value_capture(insights_file,revenue_type)\n",
    "    print(\"Step 2 completed.\")\n",
    "\n",
    "    ### Step 3\n",
    "    val_name_u = \"Units\"\n",
    "    val_name_r = \"Revenue\"\n",
    "    melty = melting_pot(insights_file, units, val_name_u)\n",
    "    malty = melting_pot(insights_file, revenue, val_name_r)\n",
    "    print(\"Step 3 completed.\")\n",
    "\n",
    "    ### Step 4\n",
    "    fatal_frame = melting_process(melty, malty)\n",
    "    print(\"Step 4 completed.\")\n",
    "\n",
    "    ### Step 5\n",
    "    exporting_porcess(fatal_frame, the_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Insights Data data conversion\")\n",
    "main()\n",
    "input(\"Fully Completed. Press any key to end.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
